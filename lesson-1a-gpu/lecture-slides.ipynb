{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0d8f45-e9d8-4675-b2b7-527c63b6c99c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lesson 1a: GPU programming in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91278adc-0762-4205-baa8-045d3a2354e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Python tools for CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9542e3-fa11-4463-b4fd-d00a3eb9cb88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05250f3e-69b5-4f0b-a1fc-df48993bed34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You've learned about CUDA in a C++ context and all about the hardware.\n",
    "\n",
    "However, Python is the world's most popular glue-language, connecting most of the tools you need in a common environment, including CUDA and C++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b37d0f-7d27-4ad2-9177-6688b53c756f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac83ada-2ff8-4487-9eb4-bbda2fd6bbb7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Can we do CUDA programming in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65808bc6-02fa-4ea4-b189-b66312d33d42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"../img/PyCUDA-documentation.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f120c-dc7a-4933-9d8b-7eea87b0e12f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235738c1-9f75-4de6-beff-4b00fa062eee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "PyCUDA is one of the oldest (2008).\n",
    "\n",
    "It has (or had?) 100% coverage of the CUDA API—anything you can do in CUDA C++ you can do in PyCUDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df95e9-da27-461c-a805-e8757cc1a04b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "module = SourceModule(r'''\n",
    "__global__ void increment(int* data) {\n",
    "    data[threadIdx.x]++;\n",
    "}\n",
    "''')\n",
    "pycuda_increment = module.get_function(\"increment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bd1dd-8e48-4c50-8b4d-350dcadfd9bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37259f3-4910-417a-bfa4-cad298b4ac37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.arange(1024, dtype=np.int32)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06fcd4-06c7-4a48-a8a0-be685d283185",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791706a0-cd47-4737-94b7-803b97934517",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pycuda_increment(cuda.InOut(data), block=(1024, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8110bb2-511d-4112-ab5e-e01ccf07c5dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425898f9-c966-47df-94b2-aa98553d0c53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee6be2-006a-4191-a79d-33d1de17e5a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "PyCUDA is just a wrapper around C++ CUDA: kernels in C++ as Python strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522f495-2565-49f7-bffd-088f7da40488",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e071331-dbb4-439b-aa16-9da1505acc66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Its value is that we can use C++ CUDA and all your favorite Python packages in the same script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2bca0b-0e4c-4107-b5eb-45ae36a7ddb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Notice, though, that CUDA kernels are designed to operate on arrays. GPUs are naturally array-oriented, like NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011441f2-8ca6-4e2e-9163-b7381f48ada7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca26c6-6270-40e3-84cb-9dec9b1ddeea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Is there a version of NumPy implemented in CUDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89a942-1fe4-4acd-bff2-f90abe87fec6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f47480-3073-4ad5-b445-173e51871da8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "array = cp.arange(1, 13)\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56db7c9-aba5-4558-ae93-bfd144506650",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4af7e6-69ce-4e10-b75f-dc5e3b0093c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785770a2-c4e9-477a-9937-f68859e49c2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "What this looks like to CUDA (in the `nsys-ui` profiler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecf449-ea53-4fd4-9482-e2fae31dce21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = cp.random.uniform(5, 10, 100_000_000)\n",
    "array.sort()\n",
    "array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1b2c114-5f98-4561-9a26-9d5ffd63c62d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"../img/nvidia-nsight-sort.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62161ee-6add-4ac3-a2d2-ad79ab4636a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "From a low-level CUDA perspective, CuPy does some surprising things:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38698b-8858-42ff-9e28-45a45c0ea1e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* It allocates its own memory pools, so a new `cp.ndarray` does not mean a new `cudaMalloc`. (You can [control it](https://docs.cupy.dev/en/stable/user_guide/memory.html), but that's the default.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f133e8-6bab-465d-9cda-ab1dcd713b23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* For performance reasons, it doesn't _perfectly_ reproduce the NumPy API. It's not _exactly_ a drop-in replacement, but it's close. (\"Drop-in and fix-up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ca4d3-4a04-4c7b-b7bf-2c84edf2dbf1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Some things that would be errors in NumPy have definitions in CuPy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323526f6-4c21-4307-b5dd-7be8fa0b43c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35154894-3bd3-4b86-b041-a6f8c95d7e43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = cp.array([0.0, 1.1, 2.2, 3.3, 4.4, 5.5])\n",
    "array[cp.array([2, 3, 5])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b609d4-f68b-4bf9-8e69-2e7893293ac6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babc4f4-cd16-487b-a614-4bef92b33d5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array[cp.array([2, 3, 5, 6, 7, 8])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9872602-989f-461c-b58a-c0db50770d8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Remember that in NumPy, an expression like the first root of the quadratic equation:\n",
    "\n",
    "$$\n",
    "x_1 = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea392cd4-65f3-4789-850f-2141db26499f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.random.uniform(5, 10, 1_000_000)\n",
    "b = np.random.uniform(10, 20, 1_000_000)\n",
    "c = np.random.uniform(-0.1, 0.1, 1_000_000)\n",
    "\n",
    "(-b + np.sqrt(b**2 - 4*a*c)) / (2*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d7487-9545-4961-8331-e2339747fb5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61addfec-f1ea-4569-b0a4-b2690e766d5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "is 9 passes over the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234c2e1-f799-4384-9c9d-279538267b6e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp1 = np.negative(b)            # -b\n",
    "tmp2 = np.square(b)              # b**2\n",
    "tmp3 = np.multiply(4, a)         # 4*a\n",
    "tmp4 = np.multiply(tmp3, c)      # tmp3*c\n",
    "del tmp3\n",
    "tmp5 = np.subtract(tmp2, tmp4)   # tmp2 - tmp4\n",
    "del tmp2, tmp4\n",
    "tmp6 = np.sqrt(tmp5)             # sqrt(tmp5)\n",
    "del tmp5\n",
    "tmp7 = np.add(tmp1, tmp6)        # tmp1 + tmp6\n",
    "del tmp1, tmp6\n",
    "tmp8 = np.multiply(2, a)         # 2*a\n",
    "np.divide(tmp7, tmp8)            # tmp7 / tmp8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953b08f-c5c1-4b64-9995-a642073d2317",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "This is also true in CuPy. Each function is a CUDA kernel and they run one after another."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e3963b1-043c-4d0f-b4a0-380d884a07d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"../img/nvidia-nsight-sqrt.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fba27-0c34-485b-b727-fcdaad2d268a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "(Doing this on a GPU is not as bad as on a CPU because GPU memory is much closer to processing, but it's still an issue.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd9876-2a03-4fe1-89a2-859df363af69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "CuPy lets you fuse operations by [JIT-compiling them](https://docs.cupy.dev/en/stable/user_guide/kernel.html). Let's compile a better alternative to `cp.pow(·, 2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98704a-517c-47bd-9078-af5efffd5858",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3ece1-a781-40db-8e26-bb2a5b1e02ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "intpow = cp.ElementwiseKernel(\"float64 x, int64 n\", \"float64 out\", '''\n",
    "    out = 1.0;\n",
    "    for (int i = 0;  i < n;  i++) {\n",
    "        out *= x;\n",
    "    }\n",
    "''', \"intpow\")\n",
    "intpow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8dd8b5-20ca-4440-82ac-93f2a916172d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02fef2-1efb-4419-87d8-caafd37963a5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = cp.random.uniform(5, 10, 1_000_000)\n",
    "b = cp.random.uniform(10, 20, 1_000_000)\n",
    "c = cp.random.uniform(-0.1, 0.1, 1_000_000)\n",
    "\n",
    "intpow(b, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e771c-dc13-45c6-a32b-e2e7033571bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf339685-1713-4f42-a85d-2c318b3828ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1480ebe-75dd-4535-bec5-b668f041d456",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "But we're back to compiling C++ in strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131ad4e-ca46-4115-8407-fb94c24eeb60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "quadratic_formula_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__ void\n",
    "quadratic_formula(const double* a, const double* b, const double* c, double* out) {\n",
    "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    out[i] = (-b[i] + sqrt(b[i]*b[i] - 4*a[i]*c[i])) / (2*a[i]);\n",
    "}\n",
    "''', \"quadratic_formula\")\n",
    "\n",
    "out = cp.empty_like(a)\n",
    "\n",
    "num_threads = 1024\n",
    "num_blocks = int(np.ceil(len(out) / 1024))\n",
    "\n",
    "quadratic_formula_kernel((num_blocks,), (num_threads,), (a, b, c, out))\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419148fe-c261-4b7a-bc90-7ba8f0fa4786",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[CUDA C keywords for function declaration](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#function-execution-space-specifiers):\n",
    "\n",
    "| Qualifier<br> Keyword | Callable<br> From | Executed<br> On | Executed<br> By |\n",
    "|:----------------------:|:------------------:|:----------------:|:----------------:|\n",
    "| \\_\\_host\\_\\_<br>(default) | Host | Host | Caller host<br> thread |\n",
    "| \\_\\_global\\_\\_ | Host<br>(or Device) | Device | New grid of<br> device threads |\n",
    "| \\_\\_device\\_\\_ | Device | Device | Caller device<br> thread |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eaf266-f2b5-4112-85f9-37727110f2cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Thus, CuPy does two things:\n",
    "\n",
    "* supercedes PyCUDA because you can JIT-compile C++ CUDA kernels\n",
    "* provides a NumPy-like array abstraction that most Python-GPU libraries recognize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54fcf0-8f17-4a81-b298-795d46835a95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "However, it's not the only one.\n",
    "\n",
    "We live in confusing times right now because most machine learning libraries define their own CUDA-capable NumPy-like arrays (and call them \"tensors\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b248b6-b685-4569-b3dc-ff44a4443a27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2aefff-8d10-40b0-a85b-37a1295e0c41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = (torch.rand(1_000_000)*5 + 5).to(\"cuda\")\n",
    "b = (torch.rand(1_000_000)*10 + 10).to(\"cuda\")\n",
    "c = (torch.rand(1_000_000)*0.2 - 0.1).to(\"cuda\")\n",
    "\n",
    "(-b + torch.sqrt(b**2 - 4*a*c)) / (2*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52adc1c-9f6e-491d-9e55-f38a549d72dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1db437-1adf-4807-a7dd-7aa8e607ea7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "There is ongoing effort to bring these all into a single standard: https://data-apis.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687685a8-194e-463b-9397-c9a8171cdc16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Compiling _Python code_ to run on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00f879-03a9-4cf9-9673-941fdf90ccd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e06163f-731b-416b-abb5-57af85b422e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Although being able to compile C++ from Python strings gives us access to all of the C++ CUDA tools—intrinsics, libraries like CUB and Thrust, etc.—there are reasons to compile _Python code_ to run on GPUs.\n",
    "\n",
    "* You can use the same Python types in and out of the GPU code.\n",
    "* You can test parts of your algorithm—slowly—in pure Python during development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60cee0-bdc6-4c4f-9804-e22374970d50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Remember that Numba can JIT-compile Python code into CPU instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace108bc-e796-4f89-86cf-4cfe0c97460e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0b62f-befe-4337-bb89-e061aff8cb61",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.njit\n",
    "def quadratic_formula_numba(a, b, c):\n",
    "    out = np.empty_like(a)\n",
    "    for i in range(len(out)):\n",
    "        out[i] = (-b[i] + np.sqrt(b[i]**2 - 4*a[i]*c[i])) / (2*a[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40faefdc-83b5-4806-8808-24944c88c4de",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0313e-37ea-49c5-a11c-816bac9e8e77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.random.uniform(5, 10, 1_000_000)\n",
    "b = np.random.uniform(10, 20, 1_000_000)\n",
    "c = np.random.uniform(-0.1, 0.1, 1_000_000)\n",
    "\n",
    "quadratic_formula_numba(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d2a49-27c8-4423-b5fd-d72f825672a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And Numba can also compile Python as CUDA functions ([through LLVM → NNVM → PTX](https://medium.com/rapids-ai/the-life-of-a-numba-kernel-a-compilation-pipeline-taking-user-defined-functions-in-python-to-cuda-71cc39b77625))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb202bc8-0733-4043-af22-52f11926a78e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f64a3-fca1-45f4-b003-360ac0d6b0b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba.cuda  # must be explicitly imported\n",
    "import math        # Numba-CUDA requires math.* instead of np.*\n",
    "\n",
    "@nb.cuda.jit\n",
    "def quadratic_formula_numba_cuda(a, b, c, out):\n",
    "    i = nb.cuda.grid(1)   # 1-dimensional\n",
    "    if i < len(out):\n",
    "        out[i] = (-b[i] + math.sqrt(b[i]**2 - 4*a[i]*c[i])) / (2*a[i])\n",
    "\n",
    "a = cp.random.uniform(5, 10, 1_000_000)\n",
    "b = cp.random.uniform(10, 20, 1_000_000)\n",
    "c = cp.random.uniform(-0.1, 0.1, 1_000_000)\n",
    "\n",
    "out = cp.empty_like(a)\n",
    "\n",
    "num_threads = 1024\n",
    "num_blocks = int(np.ceil(len(out) / 1024))\n",
    "\n",
    "quadratic_formula_numba_cuda[num_blocks, num_threads](a, b, c, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a2745-85f0-4f0f-8bd7-ffeadaabd5f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Here's `quadratic_formula_numba_cuda` in the profiler (running after CuPy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684a9dfa-4610-45bd-8c70-447f7575e0b5",
   "metadata": {},
   "source": [
    "<img src=\"../img/nvidia-nsight-quadratic.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35326f0c-6358-4f4e-91c1-950665e1ae5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Summary of your options for using CUDA in Python:\n",
    "\n",
    "* PyCUDA (obsolete)\n",
    "* CuPy as an array library like NumPy\n",
    "* CuPy to JIT-compile C++ in strings\n",
    "* Machine learning libraries have their own ~~arrays~~ \"tensors\"\n",
    "* Numba to JIT-compile (a subset of) Python as a kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584e0ac-24bb-4de7-baeb-f9d9e0daa6a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* JAX JIT-compiles (and autodiffs) array-oriented code for CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97881e1-1362-4ec0-ad82-4e441c338d89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In *lesson-4-scaling/project-1-mandelbrot.ipynb*, some of you JIT-compiled a calculation of the Mandelbrot set with JAX.\n",
    "\n",
    "If a GPU is available, JAX uses it (automatically fusing the array-oriented operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959ee03-4b74-43fa-a53c-31ba46d835f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a91d3-a7e0-404c-a13f-120282651de8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "[Mandelbrot on all accelerators](https://drive.google.com/file/d/1J0l5e0NZm5kEm5BEUDG4neN5EN0VVCnt/view?usp=sharing) demonstrates the same calculation on a variety of accelerators. The bottom line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5a8a4-2239-4fad-8fda-f3907e7f4db9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"../img/plot-mandelbrot-on-all-accelerators.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634e6ed-2007-4675-9227-fa3b24b22b64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Summary of your options for using CUDA in Python:\n",
    "\n",
    "* PyCUDA (obsolete)\n",
    "* CuPy as an array library like NumPy\n",
    "* CuPy to JIT-compile C++ in strings\n",
    "* Machine learning libraries have their own ~~arrays~~ \"tensors\"\n",
    "* Numba to JIT-compile (a subset of) Python as a kernel\n",
    "* JAX JIT-compiles (and autodiffs) array-oriented code for CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c696fec-813b-4b29-a163-4f3d33e3e753",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* The RAPIDS project provides higher-level tools, like the CuDF DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc0bf5-df4b-41ab-9bf3-64b2093f49f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "import cudf\n",
    "\n",
    "df = cudf.DataFrame({\n",
    "    \"jetid\": cp.cumsum(cp.random.poisson(0.1, 1_000_000)),\n",
    "    \"px\": cp.random.normal(0, 10, 1_000_000),\n",
    "    \"py\": cp.random.normal(0, 10, 1_000_000),\n",
    "    \"pz\": cp.random.normal(0, 10, 1_000_000),\n",
    "    \"E\": cp.random.normal(20, 10, 1_000_000),\n",
    "})\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4d65c-14d8-4ffd-9ea3-34000db1a975",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "df.groupby(\"jetid\").sum().sort_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781abc3-0c0d-4486-b074-e26fda4d2d61",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Summary of your options for using CUDA in Python:\n",
    "\n",
    "* PyCUDA (obsolete)\n",
    "* CuPy as an array library like NumPy\n",
    "* CuPy to JIT-compile C++ in strings\n",
    "* Machine learning libraries have their own ~~arrays~~ \"tensors\"\n",
    "* Numba to JIT-compile (a subset of) Python as a kernel\n",
    "* JAX JIT-compiles (and autodiffs) array-oriented code for CPU and GPU\n",
    "* The RAPIDS project provides higher-level tools, like the CuDF DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab8e6f-a42d-4834-aa7d-a7e470b81138",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Awkward Arrays can be passed as arguments to Numba, even in CUDA mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd7527-b7dd-4b86-83c0-ad3fc1dd5adf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "array = ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]])\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cb781-a473-4188-8bf1-59c4950d6605",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770af29-4336-4f77-b62e-0013eedd1d73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array_cuda = ak.to_backend(array, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9cccc2-ad28-48a0-a49a-5f13abd0150e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d61c30-cfb6-4d94-939b-4d54aa2563ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(array_cuda.layout.content.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbedb12-2f08-41b2-a478-c0806e8b58af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b6e8e-0b0c-4231-91e6-a247f3968024",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5381a495-8b9e-49d7-afe1-ba38daaee223",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.numba.register_and_check()\n",
    "\n",
    "@nb.cuda.jit(extensions=[ak.numba.cuda])\n",
    "def sum_in_cuda(array, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    out[thread_idx] = 0\n",
    "    for x in array[thread_idx]:\n",
    "        out[thread_idx] += x\n",
    "\n",
    "out = cp.empty(3, dtype=np.float64)\n",
    "\n",
    "sum_in_cuda[1, 3](array_cuda, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e8249-f031-4630-b94f-9ffe256e6a01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfadb8-e7a4-49c5-9922-963aca0743b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a966d02-a1e7-4d08-b4b9-f610b7520ac7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Awkward Arrays can be copied to and from GPUs, most operations have been implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f1567-8bf1-4d0a-898b-af9175b75832",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9bf12-d20b-4553-b57d-5ecef8776555",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.sum(array_cuda, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df53f35-b5f5-4a78-8c09-f993260f7463",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8c263-3ebd-48e8-889a-d1196a32bcf9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "But passing Awkward Arrays into `@nb.cuda.jit`-compiled functions is _entirely_ implemented.\n",
    "\n",
    "That's all we're going to use in this tutorial.\n",
    "\n",
    "(The `ak.*` functions should be ready-for-GPU by mid-2024.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffcc5c-a5bb-4bca-9f8f-755ceaeaadf5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Computing dielectron mass on a GPU with Awkward Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff13f2c-363d-4d08-aa13-1ed24de41b71",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187e1bd-b751-4e68-bb3c-48997a71489e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "with uproot.open(\"../data/SMHiggsToZZTo4L.root:Events\") as tree:\n",
    "    events_pt, events_eta, events_phi, events_charge = tree.arrays(\n",
    "        [\"Electron_pt\", \"Electron_eta\", \"Electron_phi\", \"Electron_charge\"], how=tuple\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038c824-a1d6-4e96-bbbe-4d2164200d11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e83749-15a6-4d64-a9b8-2935892b9aa0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = ak.to_backend(ak.zip({\n",
    "    \"pt\": events_pt,\n",
    "    \"eta\": events_eta,\n",
    "    \"phi\": events_phi,\n",
    "    \"charge\": events_charge,\n",
    "}), \"cuda\")\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b6a9a-cc1d-410f-9113-6a1f80e9d56d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "First, let's just write a kernel that iterates over these events, to be sure that we can do that.\n",
    "\n",
    "It's a good idea to develop CUDA workflows in small steps (_hint_ for the projects!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0bc62-a719-4666-80cb-b51c39572e68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3868e-0a41-44b7-9d91-f5e45ee26cbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit(extensions=[ak.numba.cuda])\n",
    "def iterate_over_events(events, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(events):\n",
    "        out[thread_idx] = len(events[thread_idx])\n",
    "\n",
    "num_threads = 1024\n",
    "num_blocks = int(np.ceil(len(events) / 1024))\n",
    "\n",
    "out = cp.full(len(events), -1, dtype=np.int32)\n",
    "iterate_over_events[num_blocks, num_threads](events, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef49f4-9dcc-4069-9983-112b158490a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477dc5a-d319-4153-958e-2c3cd3f9a472",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.num(events)   # one of the few functions that works in Awkward-CUDA, outside Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b1e48-e506-43af-8ac9-b3e54b370149",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now that we have that, let's iterate through the (variable number of) electrons per event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e4128-cad0-44e1-b10b-a3108e9b5055",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02872c6-7dce-4742-9996-d92e81f472b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit(extensions=[ak.numba.cuda])\n",
    "def iterate_over_electrons(events, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(events):\n",
    "        for electron in events[thread_idx]:   # for electron in THIS event\n",
    "            out[thread_idx] += electron.pt    # add up the scalar pT\n",
    "\n",
    "# same num_threads, num_blocks\n",
    "\n",
    "out = cp.zeros(len(events), dtype=np.float32)\n",
    "iterate_over_electrons[num_blocks, num_threads](events, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc3770-7b3e-4864-b7ab-99220b7853cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We want to iterate over distinct pairs of electrons `e1` and `e2`, calculating the invariant mass\n",
    "\n",
    "$$\\sqrt{2\\,{p_T}_1\\,{p_T}_2\\left(\\cosh(\\eta_1 - \\eta_2) - \\cos(\\phi_1 - \\phi_2)\\right)}$$\n",
    "\n",
    "for each pair.\n",
    "\n",
    "Let's do it in Python for a few events, first. That way, we can figure out the algorithm independently of figuring out the CUDA technicalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315962ad-bbb1-45c0-b1f8-a2c02d9fda63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c2e57-0ff8-4e5a-962b-60eced5c55b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for event in events[:10]:\n",
    "    print(f\"event with {len(event)} electrons\")\n",
    "    for i, e1 in enumerate(event):\n",
    "        for e2 in event[i + 1:]:\n",
    "            if e1.charge != e2.charge:\n",
    "                print(\n",
    "                    math.sqrt(\n",
    "                        2*e1.pt*e2.pt * (math.cosh(e1.eta - e2.eta) - math.cos(e1.phi - e2.phi))\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0367e-0868-4226-b6cf-3bfee9dac301",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now take that into CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340ac19-db9f-46b2-b159-eec69e242a48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9e57c-6d5f-4327-8e0b-757808830695",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit(extensions=[ak.numba.cuda])\n",
    "def mass_of_first_dielectron(events, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(events):\n",
    "        event = events[thread_idx]\n",
    "        for i, e1 in enumerate(event):\n",
    "            for e2 in event[i + 1:]:\n",
    "                if e1.charge != e2.charge:\n",
    "                    out[thread_idx] = math.sqrt(\n",
    "                        2*e1.pt*e2.pt * (math.cosh(e1.eta - e2.eta) - math.cos(e1.phi - e2.phi))\n",
    "                    )\n",
    "                    return\n",
    "\n",
    "# same num_threads, num_blocks\n",
    "\n",
    "out = cp.zeros(len(events), dtype=np.float32)\n",
    "mass_of_first_dielectron[num_blocks, num_threads](events, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9466485-bbf5-4a7f-9128-0237b2c5a3dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "This would be more legible as a `__device__` function.\n",
    "In CUDA programming, a `__device__` function is a function that runs on the GPU device and can be called from other device functions or from kernel functions. These functions are executed entirely on the GPU and cannot be called from the host CPU.\n",
    "\n",
    "A `__device__` function can return a value. It behaves similarly to regular C functions in this regard. When called, the function executes its code on the GPU and returns a result, which can then be used in other GPU functions or kernels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9ce72-0233-45e5-bfe2-1a1b55a32997",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b19de-87b9-488a-a98e-1f9d0406fc0a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit(extensions=[ak.numba.cuda], device=True)\n",
    "def compute_mass(event):\n",
    "    for i, e1 in enumerate(event):\n",
    "        for e2 in event[i + 1:]:\n",
    "            if e1.charge != e2.charge:\n",
    "                return math.sqrt(\n",
    "                    2*e1.pt*e2.pt * (math.cosh(e1.eta - e2.eta) - math.cos(e1.phi - e2.phi))\n",
    "                )\n",
    "    return -1\n",
    "\n",
    "@nb.cuda.jit(extensions=[ak.numba.cuda])\n",
    "def mass_of_first_dielectron(events, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(events):\n",
    "        out[thread_idx] = compute_mass(events[thread_idx])\n",
    "\n",
    "# same num_threads, num_blocks\n",
    "\n",
    "out = cp.full(len(events), -1, dtype=np.float32)\n",
    "mass_of_first_dielectron[num_blocks, num_threads](events, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb7a89-fa45-4aaf-a435-c83967fb1354",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Are these values correct? To histogram them, we need to copy the data from GPU to main memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3b1cf-5d42-487c-a147-ed6bb14de707",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a8f95-bb7e-42a6-a1aa-5f49c538796b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = out.get()\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0c8a5-67af-441b-8ca7-67c0ceeb17f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1929b-b316-4193-b793-2017fb7e81fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hist import Hist\n",
    "\n",
    "Hist.new.Reg(120, 0, 120, label=\"mass\").Double().fill(out.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f09ad8-2bc1-4b56-8074-2aeac06868dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reducing on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a93a3-66ed-4a19-89d7-8ca383b281a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab1402-6be1-4866-87fa-9cfc4e9090bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In your first project today, you'll be histogramming dielectron masses on the GPU itself, instead of copying the data back to main memory for histogramming.\n",
    "\n",
    "This is a _reduction_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51030809-bb2a-4bd1-9260-5e5df0b0df41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"../img/transformation_vs_reduction.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed01dc-caa7-459f-8f35-5ccfe07f62cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Before getting too deep, note that these operations are built into most CUDA libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236db5d6-fa96-4312-a60e-76ae57ef4f33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc522e8-355b-4438-b795-7e10f6de800a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = cp.random.normal(0, 1, 1024**2)\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e99e7b-7b43-43d5-a9b9-6c04a3e0f2c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5e4a0-4b9b-45b6-be13-6c470c8ffbca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "array.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561fb3d-ddb2-4b1b-95b6-a87ab48d1f2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ce4e3-151d-4b68-9be2-6643d312b5da",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "(Above is a difference between NumPy and CuPy: the CuPy result is a zero-dimensional array, rather than a scalar, so that the value remains on the GPU for further calculations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f299c89-dace-4512-bcde-404bc4fc7a3f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "To add all the elements of a collection with a CPU, we would ordinarily write a loop like this:\n",
    "\n",
    "```python\n",
    "result = 0\n",
    "for x in collection:\n",
    "    result += x\n",
    "```\n",
    "\n",
    "The naive equivalent of this on a GPU is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb51a0-a353-4fb7-ab2b-bc945bd7838b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def naive_sum(array, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(array):\n",
    "        out[0] += array[thread_idx]\n",
    "\n",
    "num_threads = 1024\n",
    "num_blocks = int(np.ceil(len(array) / 1024))\n",
    "\n",
    "out = cp.zeros(1, dtype=np.float64)\n",
    "naive_sum[num_blocks, num_threads](array, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a70e84-0095-48f1-9204-2dac9926d6af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ca171-dc90-4681-bccd-68c6f5622626",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "But that is not the right answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d936fd8-1bce-402c-a28f-9ab13f986406",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Here's a read-modify-write sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747cf0c-7a3d-40d2-8554-dc825f409778",
   "metadata": {},
   "source": [
    "<img src=\"../img/Race_condition.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2596e35-bbf6-4206-b19b-1c1499f0dcd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Race condition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13650dc9-3e4f-4a8e-9206-8fabce4eb586",
   "metadata": {},
   "source": [
    "<img src=\"../img/Race_condition_2.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661e293",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Here's what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a685e-4056-42b1-9286-c20dd0a75041",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = [0]\n",
    "\n",
    "class Thread:\n",
    "    def step1(self):\n",
    "        self.register = memory[0]\n",
    "    def step2(self):\n",
    "        self.register += 1\n",
    "    def step3(self):\n",
    "        memory[0] = self.register\n",
    "    \n",
    "threadA = Thread()\n",
    "threadB = Thread()\n",
    "\n",
    "# good increment\n",
    "threadA.step1(); threadA.step2(); threadA.step3()\n",
    "threadB.step1(); threadB.step2(); threadB.step3()\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cb010-c2bc-4fd0-b4ef-a171317dc952",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeeaab6-f18a-457e-8af3-627a39378630",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bad increment\n",
    "threadA.step1(); threadB.step1()\n",
    "threadA.step2(); threadB.step2()\n",
    "threadA.step3(); threadB.step3()\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bd77b-d508-476f-aa0e-c0218823c8be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "One solution to this is to prevent `threadA` and `threadB` from interleaving their steps.\n",
    "\n",
    "Instead of using `+=` to add to `out[0]`, use an atomic operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ae4f6-7bda-47ab-b0b8-841c6249c828",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6b18a-8b59-44c8-97af-5e6c6e4ff1c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def atomic_sum(array, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(array):\n",
    "        nb.cuda.atomic.add(out, 0, array[thread_idx])\n",
    "\n",
    "# same num_threads, num_blocks\n",
    "\n",
    "out = cp.zeros(1, dtype=np.float64)\n",
    "atomic_sum[num_blocks, num_threads](array, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045db33-5a9a-4d7a-a7c5-62f03efdf5f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfe25b-3a73-407d-a908-f7df52f57304",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This is correct, but all of the threads are trying to write to the same memory address at the same time. All but one of them must wait—we're losing parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879f485-7ce5-4851-9efc-57eb03416d1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Another way to do it is to avoid having any two threads write to the same array index.\n",
    "\n",
    "We can do that by adding pairs in $\\log n$ steps ($n$ is the length of the array)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656da63-a5dc-4131-b620-29ba4b0219d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78658e2a-ab63-4f65-98ac-d21aebd52ffa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <img src=\"../img/tree_reduction.png\" width=\"75%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3f4b9-0159-4e57-b5cd-75f85423c903",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <img src=\"../img/tree_reduction.png\" width=\"40%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2954ef-9e1c-4ca9-ba3c-26e72ac8f859",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array([3, 1, 7, 0, 4, 1, 6, 3])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4940030-fd02-43f6-8046-d32b3185f968",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a54cf-c085-432e-a211-e91c68fcd3cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[::2] + data[1::2]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7147b5f6-b9e8-42b3-943e-6a5640f1b15a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e97203-211e-44f9-ae9d-2f28b52e1425",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[::2] + data[1::2]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad6149-9802-475d-b2fe-4f3ad34449f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe065e-d7fd-4a8b-9bdd-e6204bc264d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[::2] + data[1::2]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ea7db-4426-4825-a375-a5fb03a115b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Here's the catch: each step has to wait until the previous step is entirely finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036bf92-2608-4338-9047-db6c808d6684",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def tree_sum_step(array, n):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < n:\n",
    "        array[thread_idx] += array[thread_idx + n]\n",
    "\n",
    "# same num_threads, num_blocks\n",
    "\n",
    "copy_of_array = array.copy()\n",
    "n = len(copy_of_array)\n",
    "while n >= 2:\n",
    "    n = n // 2\n",
    "    tree_sum_step[num_blocks, num_threads](copy_of_array, n)\n",
    "\n",
    "copy_of_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8debf0ee-493c-4025-96af-74ed28410e5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfac394-0c4f-44d1-aa01-276d14762b63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The above works, but it could be faster if we took advantage of [shared memory and block-level synchronization](https://numba.pydata.org/numba-doc/latest/cuda/memory.html#shared-memory-and-thread-synchronization), or even [warp shuffling](https://numba.readthedocs.io/en/stable/cuda-reference/kernel.html#warp-intrinsics), which are accessible in Numba-CUDA.\n",
    "\n",
    "But that would be too complicated to fit on one slide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
